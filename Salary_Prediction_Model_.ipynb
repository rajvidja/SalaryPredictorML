{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "933f8bb0",
      "metadata": {
        "id": "933f8bb0"
      },
      "source": [
        "# Machine Learning Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696e2975",
      "metadata": {
        "id": "696e2975"
      },
      "source": [
        "# Questions\n",
        "\n",
        "## 1. Your views about the problem statement?\n",
        "The problem statement is about companie named TechWorks Consulting wants to create a machine learning model to determine the salary of newly hired employees. It is important to companies to set competitive and fair salary to employees. Machine Learning model can provide objective on this problem based on many variables like college, Experience, Role, previous CTC and academic record. As a data scientist my role is to make a effective machine learning model or predictive model and evaluate its performance.\n",
        "\n",
        "\n",
        "## 2. What will be your approach to solving this task?\n",
        "\n",
        "My approach to solving this task is as follows:\n",
        "\n",
        "**(A) Data Preprocessing:**\n",
        "- Convert \"College\" into a numerical data type based on the tier of the college.\n",
        "- Convert the \"City\" field into numerical data (0 for non-metro, 1 for metro cities).\n",
        "- Create dummy variables for the \"Tier\" and \"Role\" fields.\n",
        "- Perform Exploratory Data Analysis (EDA) and check for null values.\n",
        "- Visualize various graphs to find outliers.\n",
        "- Identify outliers using percentiles (e.g., 99th and 1st percentiles) and consider them as potential outliers.\n",
        "- Treat outliers by replacing them with the mean if outliers are present.\n",
        "\n",
        "**(B) Model Selection:**\n",
        "- Choose an appropriate regression model for predicting salary. Consider regression models like Linear Regression, Ridge Regression, Lasso Regression, Decision Tree Regression, Random Forest Regressor, XG Boost Regressor, Bagging Regressor.\n",
        "- I also do Standardisation of data for models\n",
        "- Try multiple models to assess their performance.\n",
        "\n",
        "**(C) Model Training and Evaluation:**\n",
        "- Split the data into test and train datasets.\n",
        "- Train the particular model on the training dataset.\n",
        "- Evaluate the model's performance using metrics like R-Squared and Mean Squared Error.\n",
        "- Select the model with the best performance.\n",
        "\n",
        "**(D) Model Optimization:**\n",
        "- Optimize the model with cross-validation and hyperparameters.\n",
        "\n",
        "   - For Ridge and Lasso Regression, use the validation curve to tune the hyperparameters.\n",
        "   - For Decision Tree Regression, Random Forest, XGB Regressor, Bagging Regressor use GridSearchCV with parameter grids for max depth, min sample split, and min sample leaf.\n",
        "   \n",
        "**(E) Conclusion or Result:**\n",
        "- After performing the all model and get the result I will choose the best model according to R2 score and Mean Squared Error (MSE). Model which have High R2 score and Less MSE is the best one.  \n",
        "\n",
        "## **3. What were the available ML model options you had to perform this task?**\n",
        "\n",
        "For predicting employee salaries, we considered various regression models:\n",
        "\n",
        "For predicting employee salaries, we considered a range of regression models. Each model offers unique characteristics and advantages for different scenarios:\n",
        "\n",
        "1. **Simple Linear Regression:**\n",
        "   - Suitable when there's a straightforward, linear relationship between one feature and salary.\n",
        "\n",
        "2. **Multiple Linear Regression:**\n",
        "   - Useful when multiple features influence salary, allowing for more complex relationships to be considered.\n",
        "\n",
        "3. **Ridge Regression:**\n",
        "   - Prevents overfitting by adding a penalty term, making it ideal for handling multicollinearity among features.\n",
        "\n",
        "4. **Lasso Regression:**\n",
        "   - Combats overfitting and aids feature selection by encouraging some features to have zero influence on salary prediction.\n",
        "\n",
        "5. **Decision Tree Regression:**\n",
        "   - A non-linear model that captures complex relationships when the salary prediction is not linear.\n",
        "\n",
        "6. **Random Forest Regressor:**\n",
        "   - An ensemble learning model that combines multiple decision trees to improve predictive performance.\n",
        "\n",
        "7. **XG Boost Regressor:**\n",
        "   - A gradient boosting model known for its high predictive power and computational efficiency.\n",
        "\n",
        "8. **Bagging Regressor:**\n",
        "   - Utilizes Bootstrap Aggregating to create an ensemble of multiple decision tree regressors for enhanced prediction accuracy.\n",
        "\n",
        "\n",
        "To determine the best model, I'll test each and assess their performance using metrics like R-squared and Mean Squared Error. The model with the best predictive accuracy will be selected for further optimization.\n",
        "\n",
        "\n",
        "## 4. Which model’s performance is best and what could be the possible reason for that?\n",
        "I evaluated several regression models to predict the target variable, and here are the results:\n",
        "\n",
        "**Linear Regression:**\n",
        "- R-squared (R^2) - Train: 0.5335, Test: 0.5367\n",
        "- Mean Squared Error (MSE) - Train: 75026071.4080, Test: 68751323.9296\n",
        "\n",
        "**Ridge Regression:**\n",
        "- R-squared (R^2) - Train: 0.5335, Test: 0.5366\n",
        "- Mean Squared Error (MSE) - Train: 75028518.5878, Test: 68763923.8062\n",
        "\n",
        "**Lasso Regression:**\n",
        "- R-squared (R^2) - Train: 0.5332, Test: 0.5374\n",
        "- Mean Squared Error (MSE) - Train: 75080196.9627, Test: 68643390.1817\n",
        "\n",
        "**Decision Tree Regression:**\n",
        "- R-squared (R^2) - Train: 0.6137, Test: 0.5928\n",
        "- Mean Squared Error (MSE) - Train: 62125086.3121, Test: 60424631.0261\n",
        "\n",
        "**Decision Tree Regression with GridSearchCV:**\n",
        "- Best Hyperparameters: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
        "- R-squared (R^2) - Train: 0.6398, Test: 0.6032\n",
        "- Mean Squared Error (MSE) - Train: 57933285.6436, Test: 58875901.6901\n",
        "\n",
        "**Random Forest Regressor:**\n",
        "- Best Hyperparameters: RandomForestRegressor(max_depth=30, n_estimators=300)\n",
        "- R-squared (R^2) - Train: 0.9493, Test: 0.6590\n",
        "- Mean Squared Error (MSE) - Train: 8154715.2179, Test: 50597423.3677\n",
        "\n",
        "**XG Boost Regressor:**\n",
        "- Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100}\n",
        "- R-squared (R^2) - Train: 0.7758, Test: 0.6261\n",
        "- Mean Squared Error (MSE) - Train: 36064091.1440, Test: 55476872.0819\n",
        "\n",
        "**Bagging Regressor:**\n",
        "- Best Hyperparameters: BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=100, random_state=0)\n",
        "- R-squared (R^2) - Train: 0.9474, Test: 0.6537\n",
        "- Mean Squared Error (MSE) - Train: 8458815.4932, Test: 51388475.1828\n",
        "\n",
        "### Decision and Justification\n",
        "\n",
        "Based on the results, the Random Forest Regressor with the hyperparameters (max_depth=30, n_estimators=300) is the best performer for predicting the target variable.\n",
        "\n",
        "Here are the reasons for choosing this model:\n",
        "\n",
        "1. **R-squared (R^2):** The Random Forest Regressor achieves the highest R-squared value on the test dataset (0.6590) among all the models, indicating its strong predictive power and its ability to explain a significant portion of the variance in the target variable.\n",
        "\n",
        "2. **Mean Squared Error (MSE):** The Random Forest Regressor has the lowest test MSE (50597423.3677) compared to all other models, indicating that its predictions are closest to the actual values and that it provides the best fit for the data.\n",
        "\n",
        "3. **Hyperparameter Optimization:** The Random Forest Regressor has been fine-tuned with a max depth of 30 and 300 estimators, contributing to its outstanding performance.\n",
        "\n",
        "In conclusion, based on the results, I recommend using the Random Forest Regressor with max depth=30 and 300 estimators for your predictive tasks due to its high prediction accuracy.\n",
        "\n",
        "\n",
        "\n",
        "## 5. What steps can you take to improve this selected model’s performance even further?\n",
        "\n",
        "To further enhance the performance of the selected model, I took the following steps:\n",
        "\n",
        "1. **Validation Curve for Ridge and Lasso Regression:**\n",
        "    - For Ridge regression, I used a validation curve to explore different values of alpha. This helped me identify the optimal alpha value that balances bias and variance effectively.\n",
        "    - The best alpha for Ridge regression was found to be approximately 10.72.\n",
        "    \n",
        "    - For Lasso regression, a similar validation curve was employed to determine the best alpha. The optimal alpha for Lasso regression was approximately 86.97.\n",
        "    \n",
        "    - These optimal alpha values are crucial for regularizing the model and preventing overfitting.\n",
        "\n",
        "2. **GridSearchCV for Tree Regression:**\n",
        "    - To further improve the performance of the Decision Tree Regression model, I utilized GridSearchCV. This technique systematically searches through a range of hyperparameters to find the best combination that optimizes model performance.\n",
        "    - The best hyperparameters for the Decision Tree Regression model were identified as follows:\n",
        "        - 'max_depth': 4\n",
        "        - 'min_samples_leaf': 1\n",
        "        - 'min_samples_split': 5\n",
        "    - Random Forest Regressor achieved the best hyperparameters with a max depth of 30 and 300 estimators.\n",
        "     - XG Boost Regressor was optimized with a learning rate of 0.1, max depth of 4, and 100 estimators.\n",
        "      - Bagging Regressor was configured with 100 decision tree estimators.\n",
        "          \n",
        "By performing these steps, I have fine-tuned the model and optimized its hyperparameters to increase its efficiency and accuracy in making predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e0687b0",
      "metadata": {
        "id": "2e0687b0"
      },
      "source": [
        "# Execute the Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19f3ef6",
      "metadata": {
        "id": "b19f3ef6"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "db38d483",
      "metadata": {
        "id": "db38d483"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sn\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from tabulate import tabulate\n",
        "from colorama import Fore, Style\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMzbtMgFA35O"
      },
      "id": "aMzbtMgFA35O",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iieDC4kcBG8Z",
        "outputId": "c43a1852-ce2a-41e4-bc75-158a748e2257"
      },
      "id": "iieDC4kcBG8Z",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "da575e24",
      "metadata": {
        "id": "da575e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d84d1c-901e-4a7d-d463-16c211a8bfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Read the data from a CSV file named 'ML case Study.csv' and store it in a dataframe named 'df'.\n",
        "main = \"/content/drive/MyDrive/Colab Notebooks/Salary Prediction Model/ML case Study.csv\"\n",
        "df = pd.read_csv(main)\n",
        "\n",
        "\n",
        "# Read data from a CSV file named 'Colleges.csv' and store it in a dataframe named 'college_data_df'.\n",
        "clg_csv = \"/content/drive/MyDrive/Colab Notebooks/Salary Prediction Model/Colleges.csv\"\n",
        "college_data_df = pd.read_csv(clg_csv)\n",
        "\n",
        "# Read data from a CSV file named 'cities.csv' and store it in a dataframe named 'city_data_df'.\n",
        "city_csv = \"/content/drive/MyDrive/Colab Notebooks/Salary Prediction Model/cities.csv\"\n",
        "city_data_df = pd.read_csv(city_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0fbf95d",
      "metadata": {
        "id": "c0fbf95d"
      },
      "outputs": [],
      "source": [
        "# Function to assign tier labels to colleges based on 'college_data_df'.\n",
        "\n",
        "def assign_tier(row):\n",
        "     # If 'College' is in 'Tier 1', assign 'Tier 1'\n",
        "    if row['College'] in college_data_df['Tier 1'].values:\n",
        "        return 'Tier 1'\n",
        "    # If 'College' is in 'Tier 2', assign 'Tier 2'\n",
        "    elif row['College'] in college_data_df['Tier 2'].values:\n",
        "        return 'Tier 2'\n",
        "    # If 'College' is in 'Tier 3', assign 'Tier 3'\n",
        "    elif row['College'] in college_data_df['Tier 3'].values:\n",
        "        return 'Tier 3'\n",
        "    # If not found in any tier, assign 'Unknown'\n",
        "    else:\n",
        "        return 'Unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029f4e09",
      "metadata": {
        "id": "029f4e09"
      },
      "outputs": [],
      "source": [
        "# Function to assign a city type (metro or non-metro) based on 'city_data_df'.\n",
        "\n",
        "def assign_city(row):\n",
        "    if row['City'] in city_data_df['Metrio City'].values:\n",
        "        return 1\n",
        "    elif row['City'] in city_data_df['non-metro cities'].values:\n",
        "        return 0\n",
        "    else:\n",
        "        return 'unknown'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331ab319",
      "metadata": {
        "id": "331ab319"
      },
      "outputs": [],
      "source": [
        "# Apply 'assign_city' function to create a 'metro_city' column in the 'df' dataframe.\n",
        "df['metro_city'] = df.apply(assign_city, axis=1)\n",
        "\n",
        "# Apply 'assign_tier' function to create a 'Tier' column in the 'df' dataframe.\n",
        "df['Tier'] = df.apply(assign_tier, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ac852c",
      "metadata": {
        "id": "64ac852c"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fedc5d2b",
      "metadata": {
        "id": "fedc5d2b"
      },
      "source": [
        "### Create Dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d2d134",
      "metadata": {
        "id": "36d2d134"
      },
      "outputs": [],
      "source": [
        "#Create Dummies variable for 'Tier' and 'Role' columns\n",
        "df = pd.get_dummies(df, columns = ['Tier', 'Role'])\n",
        "\n",
        "#Rename the tier columns to remove the 'Tier_' prefix\n",
        "df = df.rename(columns={'Tier_Tier 1': 'Tier_1'})\n",
        "df = df.rename(columns={'Tier_Tier 2': 'Tier_2'})\n",
        "df = df.rename(columns={'Tier_Tier 3': 'Tier_3'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21f1fdb",
      "metadata": {
        "id": "e21f1fdb"
      },
      "outputs": [],
      "source": [
        "# deleting unnecessary columns\n",
        "\n",
        "del df['College']\n",
        "del df['City']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dcdd549",
      "metadata": {
        "id": "4dcdd549"
      },
      "outputs": [],
      "source": [
        "# Convert boolean columns to integer (0 or 1) in the 'df' dataframe.\n",
        "\n",
        "for column in df.select_dtypes(include=['bool']):\n",
        "    df[column] = df[column].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441aa31f",
      "metadata": {
        "id": "441aa31f"
      },
      "source": [
        "### EDD Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93510e42",
      "metadata": {
        "id": "93510e42"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49df2366",
      "metadata": {
        "id": "49df2366"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c806de29",
      "metadata": {
        "id": "c806de29"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c771bd",
      "metadata": {
        "id": "01c771bd"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65186097",
      "metadata": {
        "id": "65186097"
      },
      "source": [
        "### Check for Null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6d34f2",
      "metadata": {
        "id": "ec6d34f2"
      },
      "outputs": [],
      "source": [
        "# Calculate the count of null values for each column in the 'df' DataFrame.\n",
        "null_values = df.isna().sum()\n",
        "\n",
        "# Print columns with more than 0 null values.\n",
        "print(null_values[null_values > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c018b83",
      "metadata": {
        "id": "1c018b83"
      },
      "source": [
        "##### Note : There is no null values in this data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb69e61",
      "metadata": {
        "id": "aeb69e61"
      },
      "source": [
        "## Outliers Determination and Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05cf222c",
      "metadata": {
        "id": "05cf222c"
      },
      "outputs": [],
      "source": [
        "numerical_columns = ['Previous CTC', 'Graduation Marks', 'EXP (Month)', 'CTC']\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "for i, col in enumerate(numerical_columns, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(data=df, y=col)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48dfaed3",
      "metadata": {
        "id": "48dfaed3"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x = df['Previous CTC'], y = df['CTC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da24dfd",
      "metadata": {
        "id": "6da24dfd"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x = 'Previous job change', y = 'CTC', data = df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d37a8f6",
      "metadata": {
        "id": "6d37a8f6"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x = df['Graduation Marks'], y= df['CTC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf1255e",
      "metadata": {
        "id": "1bf1255e"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['CTC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412f7bb5",
      "metadata": {
        "id": "412f7bb5"
      },
      "outputs": [],
      "source": [
        "# Calculate the 99th percentile value of the 'Previous CTC' column in the 'df' DataFrame.\n",
        "\n",
        "upper_limit = np.percentile(df['Previous CTC'], [99])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803d00f2",
      "metadata": {
        "id": "803d00f2"
      },
      "outputs": [],
      "source": [
        "upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232146b4",
      "metadata": {
        "id": "232146b4"
      },
      "outputs": [],
      "source": [
        "#check values that highr then upper value\n",
        "\n",
        "df[(df['Previous CTC'] > upper_limit)]\n",
        "\n",
        "#there is many values that is higher then upper limit but it is in considerable range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc02879d",
      "metadata": {
        "id": "fc02879d"
      },
      "outputs": [],
      "source": [
        "#replace values that is higher then upper limit\n",
        "\n",
        "df['Previous CTC'][(df['Previous CTC'] > 3*upper_limit)] = 3*upper_limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34aa896f",
      "metadata": {
        "id": "34aa896f"
      },
      "outputs": [],
      "source": [
        "#upper limit for CTC\n",
        "\n",
        "upper_limit2 = np.percentile(df['CTC'], [99])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ebe51c",
      "metadata": {
        "id": "b8ebe51c"
      },
      "outputs": [],
      "source": [
        "upper_limit2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9121ac45",
      "metadata": {
        "id": "9121ac45"
      },
      "outputs": [],
      "source": [
        "#check values that highr then upper value\n",
        "\n",
        "df[(df['CTC'] > upper_limit2)]\n",
        "\n",
        "#there is many values that is higher then upper limit but it is in considerable range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a38149",
      "metadata": {
        "id": "45a38149"
      },
      "outputs": [],
      "source": [
        "#replace values that is higher then upper limit\n",
        "\n",
        "df['CTC'][(df['CTC'] > 3*upper_limit2)] = 3*upper_limit2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40482171",
      "metadata": {
        "id": "40482171"
      },
      "source": [
        "##### Note : There is no outliers in this data which can affect the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a977aca7",
      "metadata": {
        "id": "a977aca7"
      },
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dc7d4a",
      "metadata": {
        "id": "c9dc7d4a"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec7b030",
      "metadata": {
        "id": "bec7b030"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf47be4",
      "metadata": {
        "id": "7bf47be4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ea5cf2",
      "metadata": {
        "id": "f4ea5cf2"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into features (x_multi) and the target variable (y_multi)\n",
        "x_multi = df.loc[:, df.columns != 'CTC']\n",
        "y_multi = df['CTC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312eeecc",
      "metadata": {
        "id": "312eeecc"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets with a 20% test size\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_multi, y_multi, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcc776f",
      "metadata": {
        "id": "8bcc776f"
      },
      "outputs": [],
      "source": [
        "# Print the shapes of the training and testing sets to confirm the split\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2848ee",
      "metadata": {
        "id": "ec2848ee"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e140d5",
      "metadata": {
        "id": "20e140d5"
      },
      "source": [
        "## Liniear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6adb59bd",
      "metadata": {
        "id": "6adb59bd"
      },
      "source": [
        "### Simple Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac791e6",
      "metadata": {
        "id": "7ac791e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20591cc",
      "metadata": {
        "id": "d20591cc"
      },
      "outputs": [],
      "source": [
        "# Add a constant term to perform linear regression\n",
        "x = sn.add_constant(df['EXP (Month)'])\n",
        "\n",
        "# Create an Ordinary Least Squares (OLS) model and fit it to the data\n",
        "lm = sn.OLS(df['CTC'], x).fit()\n",
        "\n",
        "# Display a summary of the linear regression model, including statistics and coefficients.\n",
        "lm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75087b40",
      "metadata": {
        "id": "75087b40"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x=df['EXP (Month)'], y = df['CTC'], data = df, kind = 'reg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7102a4d",
      "metadata": {
        "id": "d7102a4d"
      },
      "source": [
        "### Multiple Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f3ccb5",
      "metadata": {
        "id": "06f3ccb5"
      },
      "outputs": [],
      "source": [
        "#Multiple linear Regression\n",
        "\n",
        "\n",
        "# Create a Linear Regression model\n",
        "lm_multi = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "lm_multi.fit(x_train, y_train)\n",
        "\n",
        "# Predicting values for the training and test datasets using a multiple linear regression model.\n",
        "y_train_lm_multi = lm_multi.predict(x_train)\n",
        "y_test_lm_multi = lm_multi.predict(x_test)\n",
        "\n",
        "# Calculating the R-squared (coefficient of determination) scores for the training and test datasets.\n",
        "r2_lm_multi_train = r2_score(y_train, y_train_lm_multi)\n",
        "r2_lm_multi_test = r2_score(y_test, y_test_lm_multi)\n",
        "\n",
        "# Calculating the Mean Squared Error (MSE) for the training and test datasets.\n",
        "mse_lm_multi_train = mean_squared_error(y_train, y_train_lm_multi)\n",
        "mse_lm_multi_test = mean_squared_error(y_test, y_test_lm_multi)\n",
        "\n",
        "#print the result\n",
        "print(\"Linear Regression:\")\n",
        "print(f\"R-squared (R^2) - Train: {r2_lm_multi_train:.4f}, Test: {r2_lm_multi_test:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) - Train: {mse_lm_multi_train:.4f}, Test: {mse_lm_multi_test:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5e6864a",
      "metadata": {
        "id": "f5e6864a"
      },
      "source": [
        "##### Multiple Linear Regression by using statsmodel api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ca7d87",
      "metadata": {
        "id": "a7ca7d87"
      },
      "outputs": [],
      "source": [
        "# Add a constant term to perform linear regression\n",
        "x_const = sn.add_constant(x_multi)\n",
        "# Create an Ordinary Least Squares (OLS) model and fit it to the data\n",
        "lm = sn.OLS(y_multi, x_const).fit()\n",
        "\n",
        "# Display a summary of the linear regression model, including statistics and coefficients.\n",
        "lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e010e4e1",
      "metadata": {
        "id": "e010e4e1"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6753d99d",
      "metadata": {
        "id": "6753d99d"
      },
      "source": [
        "#### Standardize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dff6c0",
      "metadata": {
        "id": "93dff6c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Standardize the data using StandardScaler from scikit-learn\n",
        "scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train_s = scaler.transform(x_train)\n",
        "x_test_s = scaler.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454b1262",
      "metadata": {
        "id": "454b1262"
      },
      "source": [
        "##### Ridge Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7800e4",
      "metadata": {
        "id": "9c7800e4"
      },
      "outputs": [],
      "source": [
        "# Define a range of alpha values for Ridge regression\n",
        "param_range = np.logspace(-2, 8, 100)\n",
        "\n",
        "# Perform cross-validated validation curve to find the best alpha for Ridge regression\n",
        "train_scores, valid_scores = validation_curve(\n",
        "    Ridge(), x_train_s, y_train, param_name=\"alpha\", param_range=param_range, cv=5, scoring='r2')\n",
        "\n",
        "# Calculate mean R-squared scores for training and validation sets\n",
        "train_mean = np.mean(train_scores, axis = 1)\n",
        "test_mean = np.mean(valid_scores, axis = 1)\n",
        "\n",
        "# Create a joint plot to visualize the relationship between log(alpha) and R-squared\n",
        "sns.jointplot(x=np.log(param_range), y=test_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033b2b5d",
      "metadata": {
        "id": "033b2b5d"
      },
      "outputs": [],
      "source": [
        "# Find the alpha value with the highest validation R-squared\n",
        "np.where(test_mean==max(test_mean))\n",
        "\n",
        "# Train a Ridge regression model with the best alpha\n",
        "lm_r_best = Ridge(alpha = param_range[30])\n",
        "lm_r_best.fit(x_train_s, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d761ad",
      "metadata": {
        "id": "55d761ad"
      },
      "source": [
        "##### Evaluate the model on the testing and training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c40d804",
      "metadata": {
        "id": "1c40d804"
      },
      "outputs": [],
      "source": [
        "# Predicting values for the training and test datasets using a Ridge regression model with the best hyperparameters.\n",
        "y_train_lm_r_best = lm_r_best.predict(x_train_s)\n",
        "y_test_lm_r_best = lm_r_best.predict(x_test_s)\n",
        "\n",
        "# Calculating the R-squared (coefficient of determination) scores for the training and test datasets.\n",
        "r2_lm_r_best_train = r2_score(y_train, y_train_lm_r_best)\n",
        "r2_lm_r_best_test = r2_score(y_test, y_test_lm_r_best)\n",
        "\n",
        "# Calculating the Mean Squared Error (MSE) for the training and test datasets.\n",
        "mse_lm_r_best_train = mean_squared_error(y_train, y_train_lm_r_best)\n",
        "mse_lm_r_best_test = mean_squared_error(y_test, y_test_lm_r_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377807f3",
      "metadata": {
        "id": "377807f3"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(\"Ridge Regression:\")\n",
        "print(f\"R-squared (R^2) - Train: {r2_lm_r_best_train:.4f}, Test: {r2_lm_r_best_test:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) - Train: {mse_lm_r_best_train:.4f}, Test: {mse_lm_r_best_test:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a94e9c6",
      "metadata": {
        "id": "1a94e9c6"
      },
      "source": [
        "## Lasso regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b4b124",
      "metadata": {
        "id": "a7b4b124"
      },
      "outputs": [],
      "source": [
        "# Define a range of alpha values for Lasso regression\n",
        "param_range2 = np.logspace(-2,8,100)\n",
        "\n",
        "# Perform cross-validated validation curve to find the best alpha for Lasso regression\n",
        "train_score_l, valid_score_l = validation_curve(Lasso(), x_train_s, y_train, param_name=\"alpha\", param_range = param_range2, cv=5, scoring='r2')\n",
        "\n",
        "# Calculate mean R-squared scores for training and validation sets with Lasso regression\n",
        "train_mean_l = np.mean(train_score_l, axis=1)\n",
        "test_mean_l = np.mean(valid_score_l, axis=1)\n",
        "\n",
        "#Create a joint plot to visualize the relationship between log(alpha) and R-squared\n",
        "sns.jointplot(x=np.log(param_range2), y=test_mean_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b775d9",
      "metadata": {
        "id": "60b775d9"
      },
      "outputs": [],
      "source": [
        "# Identify the alpha value with the highest R-squared\n",
        "np.where(test_mean_l==max(test_mean_l))\n",
        "\n",
        "# Train a Lasso regression model with the best alpha\n",
        "lm_l_best = Lasso(alpha = param_range2[39])\n",
        "lm_l_best.fit(x_train_s, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f15d66",
      "metadata": {
        "id": "d1f15d66"
      },
      "source": [
        "##### Evaluate the Lasso model on the testing and training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e65b0b1",
      "metadata": {
        "id": "9e65b0b1"
      },
      "outputs": [],
      "source": [
        "# Predicting values for the training and test datasets using a Lasso regression model with the best hyperparameters.\n",
        "y_train_lm_l_best = lm_l_best.predict(x_train_s)\n",
        "y_test_lm_l_best = lm_l_best.predict(x_test_s)\n",
        "\n",
        "# Calculating the R-squared (coefficient of determination) scores for the training and test datasets.\n",
        "r2_lm_l_best_train = r2_score(y_train, y_train_lm_l_best)\n",
        "r2_lm_l_best_test = r2_score(y_test, y_test_lm_l_best)\n",
        "\n",
        "# Calculating the Mean Squared Error (MSE) for the training and test datasets.\n",
        "mse_lm_l_best_train = mean_squared_error(y_train, y_train_lm_l_best)\n",
        "mse_lm_l_best_test = mean_squared_error(y_test, y_test_lm_l_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d97767",
      "metadata": {
        "id": "b1d97767"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(\"Lasso Regression:\")\n",
        "print(f\"R-squared (R^2) - Train: {r2_lm_l_best_train:.4f}, Test: {r2_lm_l_best_test:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) - Train: {mse_lm_l_best_train:.4f}, Test: {mse_lm_l_best_test:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c92a72af",
      "metadata": {
        "id": "c92a72af"
      },
      "source": [
        "## Decision Tree Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f475485",
      "metadata": {
        "id": "8f475485"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create a DecisionTreeRegressor with a maximum depth of 3 and fit it to the training data\n",
        "regtree = tree.DecisionTreeRegressor(max_depth = 3)\n",
        "regtree.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5070b378",
      "metadata": {
        "id": "5070b378"
      },
      "outputs": [],
      "source": [
        "# Predicting values for the training and test datasets using a regression tree model.\n",
        "y_train_regtree = regtree.predict(x_train)\n",
        "y_test_regtree = regtree.predict(x_test)\n",
        "\n",
        "# Calculating the R-squared (coefficient of determination) scores for the training and test datasets.\n",
        "r2_regtree_train = r2_score(y_train, y_train_regtree)\n",
        "r2_regtree_test = r2_score(y_test, y_test_regtree)\n",
        "\n",
        "# Calculating the Mean Squared Error (MSE) for the training and test datasets.\n",
        "mse_regtree_train = mean_squared_error(y_train, y_train_regtree)\n",
        "mse_regtree_test = mean_squared_error(y_test, y_test_regtree)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd491c4",
      "metadata": {
        "id": "3bd491c4"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(\"Decision Tree Regression:\")\n",
        "print(f\"R-squared (R^2) - Train: {r2_regtree_train:.4f}, Test: {r2_regtree_test:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) - Train: {mse_regtree_train:.4f}, Test: {mse_regtree_test:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b521d915",
      "metadata": {
        "id": "b521d915"
      },
      "outputs": [],
      "source": [
        "# Export the decision tree as a graphical visualization\n",
        "dot_data = tree.export_graphviz(regtree, out_file = None)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Display the decision tree as an image\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6576e8ae",
      "metadata": {
        "id": "6576e8ae"
      },
      "source": [
        "## Decision Tree Regression with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4449f13",
      "metadata": {
        "id": "d4449f13"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5],  # List of possible maximum depths\n",
        "    'min_samples_split': [2,4, 5,6, 10],  # List of possible values for minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4,6,8]  # List of possible values for minimum samples required at a leaf node\n",
        "}\n",
        "\n",
        "# Create a DecisionTreeRegressor\n",
        "regtree_gs = tree.DecisionTreeRegressor()\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(regtree_gs, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding mean squared error\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Get the best estimator (DecisionTreeRegressor) with the best hyperparameters\n",
        "best_regtree = grid_search.best_estimator_\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_train_pred = best_regtree.predict(x_train)\n",
        "y_test_pred = best_regtree.predict(x_test)\n",
        "\n",
        "# Calculate the R-squared scores for training data\n",
        "r2_train_dt = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the R-squared scores for testing data\n",
        "r2_test_dt = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for training data\n",
        "mse_train_dt = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for testing data\n",
        "mse_test_dt = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"R-squared (R2) for Training Data:\", r2_train_dt)\n",
        "print(\"R-squared (R2) for Testing Data:\", r2_test_dt)\n",
        "print(\"Mean Squared Error (MSE) for Training Data:\", mse_train_dt)\n",
        "print(\"Mean Squared Error (MSE) for Testing Data:\", mse_test_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf9fd3e",
      "metadata": {
        "id": "ebf9fd3e"
      },
      "source": [
        "## RandomForest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f7cf3a",
      "metadata": {
        "id": "37f7cf3a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'n_estimators': [100,  300],  # Number of trees in the forest\n",
        "    'max_depth': [20, 30],  # Maximum depth of the trees\n",
        "    'min_samples_split': [5, 10],  # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [ 2, 4]  # Minimum samples required at a leaf node\n",
        "}\n",
        "\n",
        "# Create a RandomForestRegressor\n",
        "rf_gs = RandomForestRegressor()\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_gs, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding mean squared error\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Get the best estimator (RandomForestRegressor) with the best hyperparameters\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_train_pred = best_rf.predict(x_train)\n",
        "y_test_pred = best_rf.predict(x_test)\n",
        "\n",
        "# Calculate the R-squared scores for training data\n",
        "r2_train_rf = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the R-squared scores for testing data\n",
        "r2_test_rf = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for training data\n",
        "mse_train_rf = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for testing data\n",
        "mse_test_rf = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"R-squared (R2) for Training Data:\", r2_train_rf)\n",
        "print(\"R-squared (R2) for Testing Data:\", r2_test_rf)\n",
        "print(\"Mean Squared Error (MSE) for Training Data:\", mse_train_rf)\n",
        "print(\"Mean Squared Error (MSE) for Testing Data:\", mse_test_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c4c428",
      "metadata": {
        "id": "36c4c428"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RandomForestRegressor with the best hyperparameters\n",
        "best_rf = RandomForestRegressor(n_estimators=300, max_depth=30, min_samples_split=5, min_samples_leaf=2)\n",
        "\n",
        "# Fit the model on the training data\n",
        "best_rf.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_train_pred = best_rf.predict(x_train)\n",
        "y_test_pred = best_rf.predict(x_test)\n",
        "\n",
        "# Calculate R-squared scores for training and testing data\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate Mean Squared Error for training and testing data\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"R-squared (R2) for Training Data:\", r2_train)\n",
        "print(\"R-squared (R2) for Testing Data:\", r2_test)\n",
        "print(\"Mean Squared Error (MSE) for Training Data:\", mse_train)\n",
        "print(\"Mean Squared Error (MSE) for Testing Data:\", mse_test)\n",
        "\n",
        "# Perform cross-validation to calculate training and validation scores\n",
        "cv_scores = cross_val_score(best_rf, x_train, y_train, cv=5, scoring='r2')\n",
        "cv_mse = -cross_val_score(best_rf, x_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calculate mean R-squared and MSE for cross-validation\n",
        "mean_cv_r2 = cv_scores.mean()\n",
        "mean_cv_mse = cv_mse.mean()\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"Mean R-squared (R2) for Cross-Validation:\", mean_cv_r2)\n",
        "print(\"Mean Mean Squared Error (MSE) for Cross-Validation:\", mean_cv_mse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9236996b",
      "metadata": {
        "id": "9236996b"
      },
      "source": [
        "## XG Boost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1937a7",
      "metadata": {
        "id": "9a1937a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
        "    'max_depth': [3, 4, 5],  # Maximum depth of the trees\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
        "    'min_child_weight': [1, 2, 3],  # Minimum sum of instance weight (hessian) needed in a child\n",
        "}\n",
        "\n",
        "# Create an XGBRegressor\n",
        "xgb_gs = XGBRegressor()\n",
        "\n",
        "# Create the GridSearchCV object with R2 scoring\n",
        "grid_search = GridSearchCV(xgb_gs, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding R-squared\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "best_xgb_param = grid_search.best_params_\n",
        "# Get the best estimator (XGBRegressor) with the best hyperparameters\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_train_pred = best_xgb.predict(x_train)\n",
        "y_test_pred = best_xgb.predict(x_test)\n",
        "\n",
        "# Calculate the R-squared scores for training data\n",
        "r2_train_xgb = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the R-squared scores for testing data\n",
        "r2_test_xgb = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for training data\n",
        "mse_train_xgb = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for testing data\n",
        "mse_test_xgb = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"R-squared (R2) for Training Data:\", r2_train_xgb)\n",
        "print(\"R-squared (R2) for Testing Data:\", r2_test_xgb)\n",
        "print(\"Mean Squared Error (MSE) for Training Data:\", mse_train_xgb)\n",
        "print(\"Mean Squared Error (MSE) for Testing Data:\", mse_test_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf072b2",
      "metadata": {
        "id": "edf072b2"
      },
      "source": [
        "## Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af11720",
      "metadata": {
        "id": "2af11720"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create a base regression model\n",
        "base_model = DecisionTreeRegressor()\n",
        "\n",
        "# Create a BaggingRegressor with the base model\n",
        "bagging_reg = BaggingRegressor(base_model, random_state=0)\n",
        "\n",
        "# Define the hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200]  # List of possible numbers of base models\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(bagging_reg, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding mean squared error\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "\n",
        "# Get the best estimator (BaggingRegressor) with the best hyperparameters\n",
        "best_bagging_reg = grid_search.best_estimator_\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_train_pred = best_bagging_reg.predict(x_train)\n",
        "y_test_pred = best_bagging_reg.predict(x_test)\n",
        "\n",
        "# Calculate the R-squared scores for training data\n",
        "r2_train_bagging_reg = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# Calculate the R-squared scores for testing data\n",
        "r2_test_bagging_reg = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for training data\n",
        "mse_train_bagging_reg = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test_bagging_reg = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"R-squared (R2) for Training Data:\", r2_train_bagging_reg)\n",
        "print(\"R-squared (R2) for Testing Data:\", r2_test_bagging_reg)\n",
        "print(\"Mean Squared Error (MSE) for Training Data:\", mse_train_bagging_reg)\n",
        "print(\"Mean Squared Error (MSE) for Testing Data:\", mse_test_bagging_reg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bc7c9d",
      "metadata": {
        "id": "f4bc7c9d"
      },
      "source": [
        "# Compare Different Models  "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXUu_Uv_DcjN"
      },
      "id": "lXUu_Uv_DcjN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97f92cb7",
      "metadata": {
        "id": "97f92cb7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to colorize values based on a threshold\n",
        "def colorize(value, threshold=0.6):\n",
        "    if value < threshold:\n",
        "        return f\"{Fore.RED}{value:.4f}{Style.RESET_ALL}\"\n",
        "    return f\"{Fore.GREEN}{value:.4f}{Style.RESET_ALL}\"\n",
        "\n",
        "# Define your headings\n",
        "headings = [\"Model\", \"R-squared (Train)\", \"R-squared (Test)\", \"MSE (Train)\", \"MSE (Test)\"]\n",
        "\n",
        "# Data for the table\n",
        "data = [\n",
        "    [\"Linear Regression\", colorize(r2_lm_multi_train), colorize(r2_lm_multi_test), colorize(mse_lm_multi_train), colorize(mse_lm_multi_test)],\n",
        "    [\"Ridge Regression\", colorize(r2_lm_r_best_train), colorize(r2_lm_r_best_test), colorize(mse_lm_r_best_train), colorize(mse_lm_r_best_test)],\n",
        "    [\"Lasso Regression\", colorize(r2_lm_l_best_train), colorize(r2_lm_l_best_test), colorize(mse_lm_l_best_train), colorize(mse_lm_l_best_test)],\n",
        "    [\"Decision Tree Regression\", colorize(r2_regtree_train), colorize(r2_regtree_test), colorize(mse_regtree_train), colorize(mse_regtree_test)],\n",
        "    [\"Decision Tree with GridSearchCV\", colorize(r2_train_dt), colorize(r2_test_dt), colorize(mse_train_dt), colorize(mse_test_dt)],\n",
        "    [\"Random Forest Regressor\", colorize(r2_train_rf), colorize(r2_test_rf), colorize(mse_train_rf), colorize(mse_test_rf)],\n",
        "    [\"XG Boost Regressor\", colorize(r2_train_xgb), colorize(r2_test_xgb), colorize(mse_train_xgb), colorize(mse_test_xgb)],\n",
        "    [\"Bagging Regressor\", colorize(r2_train_bagging_reg), colorize(r2_test_bagging_reg), colorize(mse_train_bagging_reg), colorize(mse_test_bagging_reg)],\n",
        "]\n",
        "\n",
        "# Print the table\n",
        "table = tabulate(data, headers=headings, tablefmt=\"fancy_grid\")\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "2U8p_8NogZwx"
      },
      "id": "2U8p_8NogZwx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "7Fmv1z4ogpnY"
      },
      "id": "7Fmv1z4ogpnY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "760c2730",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "760c2730",
        "outputId": "527fc1e1-be79-43f0-ba83-344bb8b57c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e6be7fe3d8cdf37041.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e6be7fe3d8cdf37041.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Define the RandomForestRegressor with the best hyperparameters\n",
        "best_rf = RandomForestRegressor(n_estimators=300, max_depth=30, min_samples_split=5, min_samples_leaf=2)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "best_rf.fit(x_train, y_train)\n",
        "\n",
        "def predict_salary_interface(previous_ctc, prev_job_change, graduation_marks, exp_month, metro_city, tier, role):\n",
        "    try:\n",
        "        previous_ctc = float(previous_ctc)\n",
        "        prev_job_change = float(prev_job_change)\n",
        "        graduation_marks = float(graduation_marks)\n",
        "        exp_month = float(exp_month)\n",
        "        metro_city = float(metro_city)  # Assuming 1 represents metro city\n",
        "\n",
        "        # Make a prediction using the trained model\n",
        "        input_data = {\n",
        "            'Previous CTC': [previous_ctc],\n",
        "            'Previous job change': [prev_job_change],\n",
        "            'Graduation Marks': [graduation_marks],\n",
        "            'EXP (Month)': [exp_month],\n",
        "            'metro_city': [metro_city],\n",
        "            'Tier_1': [1 if tier == 'Tier 1' else 0],\n",
        "            'Tier_2': [1 if tier == 'Tier 2' else 0],\n",
        "            'Tier_3': [1 if tier == 'Tier 3' else 0],\n",
        "            'Role_Executive': [1 if role == 'Executive' else 0],\n",
        "            'Role_Manager': [1 if role == 'Manager' else 0]\n",
        "        }\n",
        "\n",
        "        input_df = pd.DataFrame(input_data)\n",
        "        predicted_salary = best_rf.predict(input_df)[0]\n",
        "\n",
        "        # Calculate R-squared and MSE for the prediction\n",
        "        y_pred_all = best_rf.predict(x_train)\n",
        "        r2 = r2_score(y_train, y_pred_all)\n",
        "        mse = mean_squared_error(y_train, y_pred_all)\n",
        "\n",
        "        return f\"{predicted_salary:.0f}\", f\"{r2*100:.2f}%\"\n",
        "\n",
        "    except ValueError:\n",
        "        return \"Error\", \"Error in prediction\", \"Error in prediction\"\n",
        "\n",
        "# Define Gradio inputs\n",
        "inputs = [\n",
        "    gr.Number(label=\"Previous CTC\"),\n",
        "    gr.Number(label=\"Previous Job Change\"),\n",
        "    gr.Number(label=\"Graduation Marks\"),\n",
        "    gr.Number(label=\"Experience in Months\"),\n",
        "    gr.Number(label=\"Metro City (1 for Yes, 0 for No)\"),\n",
        "    gr.Dropdown(choices=[\"Tier 1\", \"Tier 2\", \"Tier 3\"], label=\"Tier\"),\n",
        "    gr.Dropdown(choices=[\"Executive\", \"Manager\"], label=\"Role\"),\n",
        "]\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_salary_interface,\n",
        "    inputs=inputs,\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Predicted CTC\"),\n",
        "        gr.Textbox(label=\"Accuracy\")\n",
        "    ],\n",
        "    title=\"Salary Prediction\",\n",
        "    description=\"Predict the salary and view overall model evaluation metrics.\",\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3a7e3b",
      "metadata": {
        "id": "fa3a7e3b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415ee652",
      "metadata": {
        "id": "415ee652"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fc8b80",
      "metadata": {
        "id": "92fc8b80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d104352b",
      "metadata": {
        "id": "d104352b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af193572",
      "metadata": {
        "id": "af193572"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1112af",
      "metadata": {
        "id": "5d1112af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca6f0f0",
      "metadata": {
        "id": "eca6f0f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}